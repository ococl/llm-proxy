package proxy

import (
	"crypto/rand"
	"encoding/json"
	"fmt"
	"time"

	"llm-proxy/logging"
	"llm-proxy/translator"
)

// ConversionMetadata stores parameter conversion details for logging
type ConversionMetadata struct {
	InputMaxTokens    interface{}
	OutputMaxTokens   int
	MaxTokensSource   string
	InputTemperature  interface{}
	OutputTemperature interface{}
	InputTopP         interface{}
	OutputTopP        interface{}
	InputStream       interface{}
	OutputStream      interface{}
	InputStop         interface{}
	OutputStop        interface{}
	InputTools        interface{}
	OutputTools       interface{}
	SystemPromptLen   int
}

// ProtocolConverter handles conversion between OpenAI and Anthropic API formats
// Now using tokligence translator internally for robust conversion
type ProtocolConverter struct {
	lastConversion *ConversionMetadata
	adapter        *translator.Adapter
}

func NewProtocolConverter() *ProtocolConverter {
	return &ProtocolConverter{
		adapter: translator.NewAdapter(),
	}
}

// GetLastConversion returns the metadata from the last conversion
func (pc *ProtocolConverter) GetLastConversion() *ConversionMetadata {
	return pc.lastConversion
}

// ConvertToAnthropic converts OpenAI format request to Anthropic format using tokligence
func (pc *ProtocolConverter) ConvertToAnthropic(openAIBody map[string]interface{}) ([]byte, error) {
	anthropicBody, err := pc.adapter.ConvertToAnthropic(openAIBody)
	if err != nil {
		logging.ProxySugar.Errorw("ConvertToAnthropic failed", "error", err)
		return nil, err
	}
	return anthropicBody, nil
}

// ConvertFromAnthropic converts Anthropic response to OpenAI format using tokligence
func (pc *ProtocolConverter) ConvertFromAnthropic(anthropicResp []byte) ([]byte, error) {
	return pc.adapter.ConvertFromAnthropic(anthropicResp)
}

// ConvertAnthropicStreamToOpenAI converts Anthropic SSE event to OpenAI SSE format
func (pc *ProtocolConverter) ConvertAnthropicStreamToOpenAI(anthropicEvent string) (string, error) {
	for _, line := range lines {
		if len(line) > 7 && line[:7] == "event: " {
			eventType = line[7:]
		} else if len(line) > 6 && line[:6] == "data: " {
			dataStr = line[6:]
		}
	}

	if dataStr == "" {
		return "", nil
	}

	var data map[string]interface{}
	if err := json.Unmarshal([]byte(dataStr), &data); err != nil {
		return "", nil
	}

	switch eventType {
	case "message_start":
		return pc.createOpenAIStreamEvent("", "", ""), nil

	case "content_block_start":
		if block, ok := data["content_block"].(map[string]interface{}); ok {
			if blockType, _ := block["type"].(string); blockType == "tool_use" {
				toolUseID, _ := block["id"].(string)
				toolName, _ := block["name"].(string)
				return pc.createOpenAIToolCallStart(toolUseID, toolName), nil
			}
		}
		return "", nil

	case "content_block_delta":
		if delta, ok := data["delta"].(map[string]interface{}); ok {
			deltaType, _ := delta["type"].(string)
			if deltaType == "text_delta" {
				if text, ok := delta["text"].(string); ok {
					return pc.createOpenAIStreamEvent(text, "", ""), nil
				}
			} else if deltaType == "input_json_delta" {
				if partialJSON, ok := delta["partial_json"].(string); ok {
					return pc.createOpenAIToolCallDelta(partialJSON), nil
				}
			}
		}

	case "content_block_stop":
		return "", nil

	case "message_delta":
		if delta, ok := data["delta"].(map[string]interface{}); ok {
			if stopReason, ok := delta["stop_reason"].(string); ok {
				return pc.createOpenAIStreamEvent("", stopReason, ""), nil
			}
		}

	case "message_stop":
		return "data: [DONE]\n\n", nil
	}

	return "", nil
}

func (pc *ProtocolConverter) createOpenAIStreamEvent(content, finishReason, toolCallDelta string) string {
	choice := map[string]interface{}{
		"index": 0,
		"delta": map[string]interface{}{},
	}

	if content != "" {
		if delta, ok := choice["delta"].(map[string]interface{}); ok {
			delta["content"] = content
		}
	}

	if finishReason != "" {
		choice["finish_reason"] = finishReason
	} else {
		choice["finish_reason"] = nil
	}

	event := map[string]interface{}{
		"id":      "chatcmpl-anthropic",
		"object":  "chat.completion.chunk",
		"created": 0,
		"model":   "claude",
		"choices": []interface{}{choice},
	}

	eventJSON, _ := json.Marshal(event)
	return "data: " + string(eventJSON) + "\n\n"
}

func (pc *ProtocolConverter) createOpenAIToolCallStart(toolUseID, toolName string) string {
	choice := map[string]interface{}{
		"index": 0,
		"delta": map[string]interface{}{
			"tool_calls": []interface{}{
				map[string]interface{}{
					"index": 0,
					"id":    toolUseID,
					"type":  "function",
					"function": map[string]interface{}{
						"name":      toolName,
						"arguments": "",
					},
				},
			},
		},
		"finish_reason": nil,
	}

	event := map[string]interface{}{
		"id":      "chatcmpl-anthropic",
		"object":  "chat.completion.chunk",
		"created": 0,
		"model":   "claude",
		"choices": []interface{}{choice},
	}

	eventJSON, _ := json.Marshal(event)
	return "data: " + string(eventJSON) + "\n\n"
}

func (pc *ProtocolConverter) createOpenAIToolCallDelta(partialJSON string) string {
	choice := map[string]interface{}{
		"index": 0,
		"delta": map[string]interface{}{
			"tool_calls": []interface{}{
				map[string]interface{}{
					"index": 0,
					"id":    "",
					"type":  "function",
					"function": map[string]interface{}{
						"arguments": partialJSON,
					},
				},
			},
		},
		"finish_reason": nil,
	}

	event := map[string]interface{}{
		"id":      "chatcmpl-anthropic",
		"object":  "chat.completion.chunk",
		"created": 0,
		"model":   "claude",
		"choices": []interface{}{choice},
	}

	eventJSON, _ := json.Marshal(event)
	return "data: " + string(eventJSON) + "\n\n"
}

func splitLines(s string) []string {
	var lines []string
	var line string
	for _, c := range s {
		if c == '\n' {
			if line != "" {
				lines = append(lines, line)
			}
			line = ""
		} else if c != '\r' {
			line += string(c)
		}
	}
	if line != "" {
		lines = append(lines, line)
	}
	return lines
}

func (pc *ProtocolConverter) ConvertOpenAIStreamStartToAnthropic(model string) []map[string]interface{} {
	var events []map[string]interface{}

	messageStart := map[string]interface{}{
		"type": "message_start",
		"message": map[string]interface{}{
			"id":            "msg_" + pc.generateID(),
			"type":          "message",
			"role":          "assistant",
			"content":       []interface{}{},
			"model":         model,
			"stop_reason":   nil,
			"stop_sequence": nil,
			"usage": map[string]interface{}{
				"input_tokens":  0,
				"output_tokens": 0,
			},
		},
	}
	events = append(events, messageStart)

	contentBlockStart := map[string]interface{}{
		"type":  "content_block_start",
		"index": 0,
		"content_block": map[string]interface{}{
			"type": "text",
			"text": "",
		},
	}
	events = append(events, contentBlockStart)

	return events
}

func (pc *ProtocolConverter) ConvertOpenAIStreamChunkToAnthropic(chunk map[string]interface{}) (map[string]interface{}, error) {
	choices, ok := chunk["choices"].([]interface{})
	if !ok || len(choices) == 0 {
		return nil, nil
	}

	choice, ok := choices[0].(map[string]interface{})
	if !ok {
		return nil, nil
	}

	delta, ok := choice["delta"].(map[string]interface{})
	if !ok {
		return nil, nil
	}

	if toolCalls, hasToolCalls := delta["tool_calls"].([]interface{}); hasToolCalls && len(toolCalls) > 0 {
		toolCall, ok := toolCalls[0].(map[string]interface{})
		if !ok {
			return nil, nil
		}

		if function, ok := toolCall["function"].(map[string]interface{}); ok {
			if arguments, ok := function["arguments"].(string); ok && arguments != "" {
				return map[string]interface{}{
					"type":  "content_block_delta",
					"index": 0,
					"delta": map[string]interface{}{
						"type":         "input_json_delta",
						"partial_json": arguments,
					},
				}, nil
			}
		}
	}

	if content, hasContent := delta["content"].(string); hasContent && content != "" {
		return map[string]interface{}{
			"type":  "content_block_delta",
			"index": 0,
			"delta": map[string]interface{}{
				"type": "text_delta",
				"text": content,
			},
		}, nil
	}

	if finishReason, hasFinish := choice["finish_reason"].(string); hasFinish && finishReason != "" {
		anthropicStopReason := "end_turn"
		if finishReason == "length" {
			anthropicStopReason = "max_tokens"
		} else if finishReason == "tool_calls" {
			anthropicStopReason = "tool_use"
		}

		return map[string]interface{}{
			"type": "message_delta",
			"delta": map[string]interface{}{
				"stop_reason":   anthropicStopReason,
				"stop_sequence": nil,
			},
			"usage": map[string]interface{}{
				"output_tokens": 0,
			},
		}, nil
	}

	return nil, nil
}

func (pc *ProtocolConverter) ConvertOpenAIStreamEndToAnthropic() []map[string]interface{} {
	var events []map[string]interface{}

	contentBlockStop := map[string]interface{}{
		"type":  "content_block_stop",
		"index": 0,
	}
	events = append(events, contentBlockStop)

	messageStop := map[string]interface{}{
		"type": "message_stop",
	}
	events = append(events, messageStop)

	return events
}

func (pc *ProtocolConverter) generateID() string {
	b := make([]byte, 16)
	_, err := rand.Read(b)
	if err != nil {
		return fmt.Sprintf("msg_%d", time.Now().UnixNano())
	}
	return fmt.Sprintf("msg_%x", b)
}

# é…ç½® OOCC ä¸Šæ¸¸ä½¿ç”¨ Anthropic åè®®æŒ‡å—

## é—®é¢˜èƒŒæ™¯

æ‚¨éœ€è¦å°† llm-proxy é…ç½®ä¸ºï¼š
- **ä¸Šæ¸¸ï¼ˆOOCCï¼‰**ï¼šä½¿ç”¨ Anthropic åŸç”Ÿ API åè®®
- **ä¸‹æ¸¸ï¼ˆå®¢æˆ·ç«¯ï¼‰**ï¼šç»§ç»­ä½¿ç”¨ OpenAI å…¼å®¹æ ¼å¼

## è§£å†³æ–¹æ¡ˆ

å·²ä¸ºé¡¹ç›®æ·»åŠ åè®®è½¬æ¢åŠŸèƒ½ï¼Œæ”¯æŒåœ¨åç«¯çº§åˆ«æˆ–æ¨¡å‹çº§åˆ«æŒ‡å®š API åè®®ã€‚

## ä»£ç å˜æ›´

### 1. é…ç½®ç»“æ„æ‰©å±• (`src/config/config.go`)

```go
type Backend struct {
    Name     string `yaml:"name"`
    URL      string `yaml:"url"`
    APIKey   string `yaml:"api_key,omitempty"`
    Enabled  *bool  `yaml:"enabled,omitempty"`
    Protocol string `yaml:"protocol,omitempty"` // æ–°å¢ï¼šæ”¯æŒ "openai" æˆ– "anthropic"
}

type ModelRoute struct {
    Backend  string `yaml:"backend"`
    Model    string `yaml:"model"`
    Priority int    `yaml:"priority"`
    Enabled  *bool  `yaml:"enabled,omitempty"`
    Protocol string `yaml:"protocol,omitempty"` // æ–°å¢ï¼šæ¨¡å‹çº§åˆ«åè®®è¦†ç›–
}
```

### 2. åè®®è½¬æ¢å™¨ (`src/proxy/protocol.go`)

æ–°å¢ `ProtocolConverter` ç±»ï¼Œè´Ÿè´£ï¼š
- OpenAI â†’ Anthropic è¯·æ±‚æ ¼å¼è½¬æ¢
- Anthropic â†’ OpenAI å“åº”æ ¼å¼è½¬æ¢
- æ¶ˆæ¯æ ¼å¼ã€å·¥å…·è°ƒç”¨ã€å‚æ•°æ˜ å°„ç­‰

### 3. ä»£ç†é€»è¾‘æ›´æ–° (`src/proxy/proxy.go`)

- æ ¹æ®é…ç½®è‡ªåŠ¨é€‰æ‹©åè®®
- è½¬æ¢è¯·æ±‚ä½“æ ¼å¼
- è®¾ç½®æ­£ç¡®çš„ HTTP å¤´éƒ¨ï¼ˆ`x-api-key` vs `Authorization`ï¼‰
- æ·»åŠ  Anthropic å¿…éœ€çš„å¤´éƒ¨ï¼ˆ`anthropic-version`ï¼‰

## é…ç½®æ–¹æ³•

### æ–¹å¼ 1ï¼šåç«¯çº§åˆ«é…ç½®ï¼ˆæ¨èï¼‰

é€‚ç”¨äºæ•´ä¸ªåç«¯ç»Ÿä¸€ä½¿ç”¨ä¸€ç§åè®®ï¼š

```yaml
backends:
  - name: "oocc"
    url: "https://your-oocc.com/v1"
    api_key: "sk-ant-xxx"
    protocol: "anthropic"  # ğŸ‘ˆ å…³é”®é…ç½®
    enabled: true

models:
  "anthropic/claude-sonnet-4":
    routes:
      - backend: "oocc"
        model: "claude-sonnet-4-20250514"
        priority: 1
```

### æ–¹å¼ 2ï¼šæ¨¡å‹çº§åˆ«é…ç½®

é€‚ç”¨äºåŒä¸€åç«¯éœ€è¦æ··åˆä½¿ç”¨ä¸åŒåè®®ï¼š

```yaml
backends:
  - name: "mixed-backend"
    url: "https://your-endpoint.com/v1"
    api_key: "sk-xxx"
    protocol: "openai"  # åç«¯é»˜è®¤åè®®

models:
  "claude-sonnet-4":
    routes:
      - backend: "mixed-backend"
        model: "claude-sonnet-4"
        protocol: "anthropic"  # ğŸ‘ˆ æ¨¡å‹çº§åˆ«è¦†ç›–
        priority: 1
  
  "gpt-4":
    routes:
      - backend: "mixed-backend"
        model: "gpt-4"
        # ä½¿ç”¨åç«¯é»˜è®¤çš„ openai åè®®
        priority: 1
```

## åè®®ä¼˜å…ˆçº§

```
æ¨¡å‹çº§åˆ« protocol > åç«¯çº§åˆ« protocol > é»˜è®¤ "openai"
```

## åè®®è½¬æ¢ç»†èŠ‚

### OpenAI â†’ Anthropic

1. **æ¶ˆæ¯æ ¼å¼**ï¼š
   - æå– `system` è§’è‰²æ¶ˆæ¯ â†’ Anthropic `system` å­—æ®µ
   - ä¿ç•™ `user` å’Œ `assistant` æ¶ˆæ¯

2. **å‚æ•°æ˜ å°„**ï¼š
   ```
   max_tokens / max_completion_tokens â†’ max_tokens
   stop â†’ stop_sequences
   temperature, top_p, stream â†’ ç›´æ¥ä¼ é€’
   ```

3. **HTTP å¤´éƒ¨**ï¼š
   ```
   Authorization: Bearer xxx â†’ x-api-key: xxx
   æ·»åŠ : anthropic-version: 2023-06-01
   ç§»é™¤: OpenAI-Organization, OpenAI-Project
   ```

4. **å·¥å…·è°ƒç”¨**ï¼š
   ```json
   // OpenAI æ ¼å¼
   {"type": "function", "function": {"name": "...", "parameters": {...}}}
   
   // è½¬æ¢ä¸º Anthropic æ ¼å¼
   {"name": "...", "description": "...", "input_schema": {...}}
   ```

### Anthropic â†’ OpenAI

å“åº”è‡ªåŠ¨è½¬æ¢å› OpenAI æ ¼å¼ï¼Œå®¢æˆ·ç«¯æ— æ„ŸçŸ¥ã€‚

## å®¢æˆ·ç«¯ä½¿ç”¨

å®¢æˆ·ç«¯ä»£ç **æ— éœ€ä¿®æ”¹**ï¼Œç»§ç»­ä½¿ç”¨ OpenAI SDKï¼š

```python
from openai import OpenAI

client = OpenAI(
    api_key="sk-your-unified-api-key",
    base_url="http://localhost:8080/v1"
)

# ä»£ç†ä¼šè‡ªåŠ¨è½¬æ¢ä¸º Anthropic åè®®å‘é€åˆ° OOCC
response = client.chat.completions.create(
    model="anthropic/claude-sonnet-4",
    messages=[
        {"role": "system", "content": "You are a helpful assistant."},
        {"role": "user", "content": "Hello!"}
    ]
)
```

## é…ç½®ç¤ºä¾‹æ–‡ä»¶

- **å®Œæ•´ç¤ºä¾‹**ï¼š`src/config.anthropic.example.yaml`
- **è¯¦ç»†æ–‡æ¡£**ï¼š`docs/anthropic_protocol_config.md`

## æµ‹è¯•æ­¥éª¤

1. **æ›´æ–°é…ç½®æ–‡ä»¶**ï¼š
   ```bash
   cp src/config.anthropic.example.yaml config.yaml
   # ä¿®æ”¹ OOCC çš„ URL å’Œ API Key
   ```

2. **ç¼–è¯‘è¿è¡Œ**ï¼š
   ```bash
   cd src
   go build -o ../llm-proxy
   cd ..
   ./llm-proxy -config config.yaml
   ```

3. **æµ‹è¯•è¯·æ±‚**ï¼š
   ```bash
   curl http://localhost:8080/v1/chat/completions \
     -H "Content-Type: application/json" \
     -H "Authorization: Bearer sk-your-unified-api-key" \
     -d '{
       "model": "anthropic/claude-sonnet-4",
       "messages": [{"role": "user", "content": "Hello!"}]
     }'
   ```

4. **æŸ¥çœ‹æ—¥å¿—**ï¼š
   ```bash
   tail -f logs/general.log
   ```
   
   åº”è¯¥èƒ½çœ‹åˆ°ç±»ä¼¼æ—¥å¿—ï¼š
   ```
   åè®®: anthropic
   å·²è½¬æ¢ä¸ºAnthropicåè®®æ ¼å¼
   ```

## æ³¨æ„äº‹é¡¹

1. **max_tokens å‚æ•°**ï¼šAnthropic è¦æ±‚å¿…é¡»æä¾›ï¼Œä»£ç†ä¼šè‡ªåŠ¨è®¾ç½®é»˜è®¤å€¼ 4096

2. **æµå¼å“åº”**ï¼šä¸¤ç§åè®®çš„ SSE æ ¼å¼ä¸åŒï¼Œä»£ç†ä¼šè‡ªåŠ¨å¤„ç†

3. **é”™è¯¯å¤„ç†**ï¼šåè®®è½¬æ¢å¤±è´¥ä¼šè®°å½•è¯¦ç»†æ—¥å¿—å¹¶è§¦å‘å›é€€æœºåˆ¶

4. **è°ƒè¯•æ¨¡å¼**ï¼šè®¾ç½® `logging.debug_mode: true` å¯æŸ¥çœ‹è¯¦ç»†çš„åè®®è½¬æ¢æ—¥å¿—

## æ•…éšœæ’æŸ¥

### é—®é¢˜ï¼šè¯·æ±‚å¤±è´¥ï¼Œæç¤ºæ ¼å¼é”™è¯¯

**æ£€æŸ¥**ï¼š
- ç¡®è®¤ `protocol: "anthropic"` é…ç½®æ­£ç¡®
- æŸ¥çœ‹æ—¥å¿—ä¸­æ˜¯å¦æœ‰ "å·²è½¬æ¢ä¸ºAnthropicåè®®æ ¼å¼"
- æ£€æŸ¥ OOCC ç«¯ç‚¹æ˜¯å¦æ”¯æŒ Anthropic åŸç”Ÿæ ¼å¼

### é—®é¢˜ï¼šè®¤è¯å¤±è´¥

**æ£€æŸ¥**ï¼š
- Anthropic ä½¿ç”¨ `x-api-key` å¤´éƒ¨ï¼Œä¸æ˜¯ `Authorization`
- ç¡®è®¤ API Key æ ¼å¼æ­£ç¡®ï¼ˆé€šå¸¸ä»¥ `sk-ant-` å¼€å¤´ï¼‰

### é—®é¢˜ï¼šå“åº”æ ¼å¼é”™è¯¯

**æ£€æŸ¥**ï¼š
- ç¡®è®¤ OOCC è¿”å›çš„æ˜¯æ ‡å‡† Anthropic å“åº”æ ¼å¼
- æŸ¥çœ‹é”™è¯¯æ—¥å¿—ä¸­çš„å“åº”å†…å®¹

## åç»­ä¼˜åŒ–å»ºè®®

1. **æµå¼å“åº”è½¬æ¢**ï¼šå½“å‰å®ç°å¯èƒ½éœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ– SSE æ ¼å¼è½¬æ¢
2. **æ›´å¤šå‚æ•°æ”¯æŒ**ï¼šå¦‚ Anthropic çš„ `thinking` å‚æ•°ç­‰
3. **å“åº”ç¼“å­˜**ï¼šè€ƒè™‘æ·»åŠ  Anthropic Prompt Caching æ”¯æŒ
4. **æµ‹è¯•è¦†ç›–**ï¼šæ·»åŠ åè®®è½¬æ¢çš„å•å…ƒæµ‹è¯•

## ç›¸å…³æ–‡ä»¶

- `src/config/config.go` - é…ç½®ç»“æ„å®šä¹‰
- `src/proxy/protocol.go` - åè®®è½¬æ¢é€»è¾‘
- `src/proxy/proxy.go` - ä»£ç†ä¸»é€»è¾‘
- `src/config.anthropic.example.yaml` - é…ç½®ç¤ºä¾‹
- `docs/anthropic_protocol_config.md` - è¯¦ç»†æ–‡æ¡£

